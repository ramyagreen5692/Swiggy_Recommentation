{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaning complete. Cleaned data saved as 'cleaned_data.csv'\n",
      "Shape of cleaned data: (61421, 11)\n"
     ]
    }
   ],
   "source": [
    "#Data loading and cleaning\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "file_path = r\"D:\\Swiggy\\data\\swiggy.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop rows with missing critical fields\n",
    "df = df.dropna(subset=['name', 'rating', 'cost', 'cuisine'])\n",
    "\n",
    "# Remove rows with invalid ratings (e.g., '--')\n",
    "df = df[df['rating'] != '--']\n",
    "\n",
    "# Convert 'rating' to float\n",
    "df['rating'] = df['rating'].astype(float)\n",
    "\n",
    "# Clean 'cost': remove ₹ symbol and commas\n",
    "df['cost'] = df['cost'].str.replace('₹', '', regex=False).str.replace(',', '', regex=False)\n",
    "\n",
    "# Convert cost to integer, drop rows with errors\n",
    "df['cost'] = pd.to_numeric(df['cost'], errors='coerce')\n",
    "df = df.dropna(subset=['cost'])\n",
    "df['cost'] = df['cost'].astype(int)\n",
    "\n",
    "# Reset index\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Save cleaned data\n",
    "df.to_csv(r\"D:\\Swiggy\\data\\cleaned_data.csv\", index=False)\n",
    "\n",
    "print(\"✅ Cleaning complete. Cleaned data saved as 'cleaned_data.csv'\")\n",
    "print(f\"Shape of cleaned data: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Encoding complete. Saved to 'encoded_data.csv'\n",
      "Shape of encoded data: (61421, 895)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pickle\n",
    "\n",
    "# Load the cleaned data\n",
    "cleaned_df = pd.read_csv(r\"D:\\Swiggy\\data\\cleaned_data.csv\")\n",
    "\n",
    "# STEP 1: Expand 'cuisine' column into multiple values\n",
    "# Split comma-separated cuisines into list\n",
    "cleaned_df['cuisine'] = cleaned_df['cuisine'].str.split(',')\n",
    "\n",
    "# Trim whitespace from each cuisine\n",
    "cleaned_df['cuisine'] = cleaned_df['cuisine'].apply(lambda x: [i.strip() for i in x])\n",
    "\n",
    "# Create cuisine dummy variables\n",
    "cuisine_dummies = cleaned_df['cuisine'].explode().str.get_dummies().groupby(level=0).sum()\n",
    "\n",
    "# STEP 2: One-hot encode the 'city' column\n",
    "city_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')  # <-- updated line\n",
    "city_encoded = city_encoder.fit_transform(cleaned_df[['city']])\n",
    "city_df = pd.DataFrame(city_encoded, columns=city_encoder.get_feature_names_out(['city']))\n",
    "\n",
    "\n",
    "# STEP 3: Combine numerical + encoded data\n",
    "encoded_df = pd.concat([\n",
    "    cleaned_df[['rating', 'cost']].reset_index(drop=True),\n",
    "    city_df.reset_index(drop=True),\n",
    "    cuisine_dummies.reset_index(drop=True)\n",
    "], axis=1)\n",
    "\n",
    "# Save encoded data\n",
    "encoded_df.to_csv(r\"D:\\Swiggy\\data\\encoded_data.csv\", index=False)\n",
    "\n",
    "# Save encoder for city (if needed later in app)\n",
    "with open(r\"D:\\Swiggy\\data\\encoder.pkl\", 'wb') as f:\n",
    "    pickle.dump(city_encoder, f)\n",
    "\n",
    "print(\"✅ Encoding complete. Saved to 'encoded_data.csv'\")\n",
    "print(f\"Shape of encoded data: {encoded_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bharanidharan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but OneHotEncoder was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 Top Recommended Restaurants:\n",
      "\n",
      "                              name                       city  rating  cost  \\\n",
      "48893                    Food Land                  North-goa     4.8   400   \n",
      "18898         Royal Biryani Darbar          Mogappair,Chennai     4.3   350   \n",
      "9432   RNR Biryani - Taste of 1953  Electronic City,Bangalore     4.3   350   \n",
      "8527   RNR Biryani - Taste of 1953  Kanakapura Road,Bangalore     4.3   350   \n",
      "4041            AMBUR STAR BIRYANI      Koramangala,Bangalore     4.1   330   \n",
      "\n",
      "                    cuisine                                            address  \n",
      "48893  South Indian,Biryani  Food Land, Baga Beach,Bardez.North Goa 403516,...  \n",
      "18898  Biryani,South Indian  Royal Biryani Darbar, Plot No 152BRam Nagar si...  \n",
      "9432   Biryani,South Indian  RNR Biryani - Taste of 1953, Taste of 1953, No...  \n",
      "8527   Biryani,South Indian  RNR Biryani - Taste of 1953, Rainbow Centrum, ...  \n",
      "4041   Biryani,South Indian  AMBUR STAR BIRYANI, 104,JATTI BUILDING,1ST MAI...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pickle\n",
    "\n",
    "# Load cleaned and encoded data\n",
    "cleaned_df = pd.read_csv(r\"D:\\Swiggy\\data\\cleaned_data.csv\")\n",
    "encoded_df = pd.read_csv(r\"D:\\Swiggy\\data\\encoded_data.csv\")\n",
    "\n",
    "# Load encoder\n",
    "with open(r\"D:\\Swiggy\\data\\encoder.pkl\", 'rb') as f:\n",
    "    city_encoder = pickle.load(f)\n",
    "\n",
    "# Recommendation function\n",
    "def recommend_restaurants(city, cuisines, min_rating, max_cost, top_n=5):\n",
    "    # 1. Encode city\n",
    "    city_encoded = city_encoder.transform([[city]])\n",
    "    city_df = pd.DataFrame(city_encoded, columns=city_encoder.get_feature_names_out(['city']))\n",
    "    \n",
    "    # 2. Encode cuisines\n",
    "    # Get cuisine columns from encoded_df\n",
    "    all_cuisine_columns = [col for col in encoded_df.columns if col not in ['rating', 'cost'] and not col.startswith('city_')]\n",
    "    cuisine_vec = [1 if cuisine in cuisines else 0 for cuisine in all_cuisine_columns]\n",
    "    cuisine_df = pd.DataFrame([cuisine_vec], columns=all_cuisine_columns)\n",
    "    \n",
    "    # 3. Combine input features\n",
    "    input_features = pd.DataFrame({\n",
    "        'rating': [min_rating],\n",
    "        'cost': [max_cost]\n",
    "    })\n",
    "    user_vector = pd.concat([input_features, city_df, cuisine_df], axis=1)\n",
    "    \n",
    "    # 4. Match column order\n",
    "    user_vector = user_vector[encoded_df.columns]\n",
    "    \n",
    "    # 5. Compute cosine similarity\n",
    "    similarities = cosine_similarity(user_vector, encoded_df)[0]\n",
    "    top_indices = similarities.argsort()[::-1][:top_n]\n",
    "    \n",
    "    # 6. Get results from original cleaned data\n",
    "    recommended = cleaned_df.iloc[top_indices][['name', 'city', 'rating', 'cost', 'cuisine', 'address']]\n",
    "    return recommended\n",
    "\n",
    "# 🔍 Example usage:\n",
    "results = recommend_restaurants(\n",
    "    city=\"Chennai\",\n",
    "    cuisines=[\"South Indian\", \"Biryani\"],\n",
    "    min_rating=4.0,\n",
    "    max_cost=300,\n",
    "    top_n=5\n",
    ")\n",
    "\n",
    "print(\"📌 Top Recommended Restaurants:\\n\")\n",
    "print(results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
